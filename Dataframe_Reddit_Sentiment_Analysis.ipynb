{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "name": "Dataframe- Reddit Sentiment Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/barbara-balcon/Reddit-Sentiment-Analysis/blob/main/Dataframe_Reddit_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Niy1OBa4Aort"
      },
      "source": [
        "# Obtaining Reddit data: accessing the Reddit API\n",
        "The first preliminary step to performing any kind of sentiment analysis on Reddit data is establishing a **Reddit instance** via **API**. This can be done with the **Python Reddit API Wrapper (PRAW)**, see documentation: https://praw.readthedocs.io/en/latest/\n",
        "\n",
        "In order to access the API, a **Reddit account** is needed, login details below.\n",
        "> E-mail: barbara.balcon@studbocconi.it\n",
        "Username: thesis_3078976\n",
        "Password: class_of_2021\n",
        "\n",
        "I created an **application** at the following link: https://www.reddit.com/prefs/apps\n",
        "> - Name: Sentiment Analysis\n",
        "I selected 'script' (Script for personal use. Will only have access to the developers accounts\n",
        "description)\n",
        "- Description: Data will be used to perform sentiment analysis\n",
        "- About url: blank\n",
        "- Redirect url: http://www.example.com/unused/redirect/url (this is empty)\n",
        "\n",
        "After creating the app, the following is generated.\n",
        "> ID: L_wWPUNiMBmn1Q  \n",
        "Secret: bUYKyV21W3xXK4GzXsY5tsNzpG3pRw\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWlaOeb7BJlz"
      },
      "source": [
        "#installing packages we will later import and use\n",
        "!pip install praw\n",
        "!pip install mysql.connector\n",
        "!pip install vaderSentiment\n",
        "!pip install unidecode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjNfB3FzBGvx"
      },
      "source": [
        ""
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tjzS6QfAor0"
      },
      "source": [
        "#import of the relevant libraries \n",
        "import praw\n",
        "import pandas as pd\n",
        "from praw.models import MoreComments"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTGPUPXAAor3"
      },
      "source": [
        "#create a reddit connection with reddit api details\n",
        "reddit=praw.Reddit(client_id='L_wWPUNiMBmn1Q', client_secret='bUYKyV21W3xXK4GzXsY5tsNzpG3pRw', user_agent='ua')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GD5wcfQSAor4"
      },
      "source": [
        "The following pulls the **five hottest posts** in the subreddit wallstreetbets, printing the title and ID of each. This step is for illustrating purposes only and does *not* feed into the sentiment analysis performed later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzhpS_taAor4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "955085b6-38c0-4ffd-a008-08b1370b0131"
      },
      "source": [
        "subreddit=reddit.subreddit('wallstreetbets')\n",
        "for submission in subreddit.hot(limit=5):\n",
        "    print(submission.title)\n",
        "    print('Submission ID = ', submission.id, '\\n')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "What Are Your Moves Tomorrow, April 06, 2021\n",
            "Submission ID =  mktg0s \n",
            "\n",
            "WSB Rules - Please Read Before Posting\n",
            "Submission ID =  mkkfno \n",
            "\n",
            "I have come to the realization that a stock with this amount of volatility that Game stop has does not give a FLYING F*CK (smooth brains - the star represents a U) about Technical Analysis!\n",
            "Submission ID =  ml0bsy \n",
            "\n",
            "26k-> 99k in a day . Mainly thanks to $SPY yolo ðŸ˜€\n",
            "Submission ID =  mktvom \n",
            "\n",
            "I built a tool for us to track US Representatives Stock Trades\n",
            "Submission ID =  mkpdr9 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2bT56O_Aor6"
      },
      "source": [
        "# Alternative storage of the data: creating a dataframe\n",
        "\n",
        "\n",
        "As a more readily accessible alternative to a SQL database, in this version of the code we are creating a Pandas dataframe. \n",
        "\n",
        "\n",
        "A dataframe can be thought of as table: each column is a characteristic of a post in r/wallstreetbets e.g. author, and each row stores a post.\n",
        "\n",
        "\n",
        "The database has defined columns, but it is empty for now, will be populated in subsequent steps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txrS9U2KAor8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbfd0908-1ac7-4407-f53f-0d39c0aa78b5"
      },
      "source": [
        "import pandas as pd\n",
        "import datetime \n",
        "import time #packages for handling date and time data\n",
        "\n",
        " \n",
        "df = pd.DataFrame(columns=['Current time','Subreddit','Author','Title','Body','Sentiment'])\n",
        "#creation of a database for storing reddit data \n",
        "\n",
        "print(df)\n",
        "#creating variables we are about to create instances of when analysing sentiment\n",
        " "
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Empty DataFrame\n",
            "Columns: [Current time, Subreddit, Author, Title, Body, Sentiment]\n",
            "Index: []\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCz06AUkAor-"
      },
      "source": [
        "# Performing post sentiment analysis and storing the results\n",
        "\n",
        "## Introduction to VADER\n",
        "Now we are ready to **live stream** comments from Reddit and perform sentiment analysis via **VADER** (Valence Aware Dictionary and sEntiment Reasoner). It is an open-source tool that was designed for social media specifically. It is lexicon and rule-based. \n",
        "See: \n",
        "> Hutto, C.J. & Gilbert, E.E. (2014). *VADER: A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text.* Eighth International Conference on Weblogs and Social Media (ICWSM-14). Ann Arbor, MI, June 2014.\n",
        "\n",
        "It returns a **polarity score (-1, +1)** for each post: a normalized, weighted composite score that acts as a metric of the overall sentiment of a given post.  \n",
        "\n",
        "## Storing the data in the database\n",
        "In the *while* loop, we are **populating the table** in the SQL database we created earlier with data streamed from the Reddit API. For each post, we include:\n",
        "- current date and time;\n",
        "- subreddit (wallstreetbets);\n",
        "- author;\n",
        "- title;\n",
        "- body;\n",
        "- compound sentiment score\n",
        "\n",
        "## A practical note\n",
        "Since this is live streaming, the code cell below will keep running indefinitely: just use the 'stop' button to interrupt it.This might return:\n",
        "\n",
        "> KeyboardInterrupt                         Traceback (most recent call last)\n",
        "\n",
        "It is not an actual error, it just indicates that the run was manually interrupted. Also, please ignore the message calling for use of anyncronous PRAW,  the current one works just fine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBGDRp0kAor-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "56feea84-d499-4b6a-cf58-26330a444ae6"
      },
      "source": [
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "analyzer= SentimentIntensityAnalyzer() #just an abbreviation \n",
        "from unidecode import unidecode #a package for dealing with Unicode\n",
        "\n",
        "\n",
        "columns=list(df)\n",
        "data=[]\n",
        "body=''\n",
        "while True:\n",
        "    try:\n",
        "        \n",
        "        subreddit = reddit.subreddit('wallstreetbets')\n",
        "        for comment in subreddit.stream.comments(skip_existing=True):\n",
        "\n",
        "                vs = analyzer.polarity_scores(unidecode(body))\n",
        "                sentiment = vs['compound'] #we are interested in the compound score\n",
        "                \n",
        "                if len(str(comment.body)) < 2000:\n",
        "                    body = str(comment.body)\n",
        "                elif len(str(comment.body)) > 2000:\n",
        "                    body = \"data is too large\"\n",
        "                \n",
        "                values = [datetime.datetime.now(), str(comment.subreddit),\n",
        "                          str(comment.author), str(comment.link_title), body, sentiment]\n",
        "                \n",
        "               \n",
        "                zipped=zip(columns, values)\n",
        "                a_dict=dict(zipped)\n",
        "                data.append(a_dict)\n",
        "\n",
        "\n",
        "                df=df.append(data, True)\n",
        "    except Exception as e:\n",
        "        print(str(e))\n",
        "        time.sleep(10)\n",
        "'''We keep an exception so that in case of error we do not hit\n",
        "the API multiple times''' "
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-c698399cb8ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0msubreddit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreddit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubreddit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wallstreetbets'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mcomment\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubreddit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskip_existing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mvs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolarity_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munidecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/praw/models/util.py\u001b[0m in \u001b[0;36mstream_generator\u001b[0;34m(function, pause_after, skip_existing, attribute_name, exclude_before, **function_kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexponential_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1R4pQmuJFvBJ"
      },
      "source": [
        "print(df) # prints the full content of the dataframe\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "id": "7xjN15vpIN2C",
        "outputId": "f003edd7-4b93-44a0-d64d-b43738cdfa72"
      },
      "source": [
        "df.head() # returns the first 5 rows of the dataframe (recommended)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Current time</th>\n",
              "      <th>Subreddit</th>\n",
              "      <th>Author</th>\n",
              "      <th>Title</th>\n",
              "      <th>Body</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-04-06 08:50:07.441350</td>\n",
              "      <td>wallstreetbets</td>\n",
              "      <td>mamadidntraiseabitch</td>\n",
              "      <td>What Are Your Moves Tomorrow, April 06, 2021</td>\n",
              "      <td>What happened during that one year?</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-04-06 08:50:07.441350</td>\n",
              "      <td>wallstreetbets</td>\n",
              "      <td>mamadidntraiseabitch</td>\n",
              "      <td>What Are Your Moves Tomorrow, April 06, 2021</td>\n",
              "      <td>What happened during that one year?</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-04-06 08:50:11.830204</td>\n",
              "      <td>wallstreetbets</td>\n",
              "      <td>VisualMod</td>\n",
              "      <td>If only Iâ€™d have known...</td>\n",
              "      <td>I am a bot. You submitted a picture of a banne...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Current time  ... Sentiment\n",
              "0 2021-04-06 08:50:07.441350  ...       0.0\n",
              "1 2021-04-06 08:50:07.441350  ...       0.0\n",
              "2 2021-04-06 08:50:11.830204  ...       0.0\n",
              "\n",
              "[3 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAopmyuSJOTc"
      },
      "source": [
        "df.to_csv('df.csv')# saves the file as a csv in this cloud environment\n",
        "from google.colab import files\n",
        "files.download('df.csv') # downloads the file to the local machine\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvGLk7HnpGbR"
      },
      "source": [
        "To **open the csv file** created: click on the folder icon in the top left of the screen, then double-click on df.csv: it will open in the current window."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9tXLHiNIeBi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plO5lTIkF3ll"
      },
      "source": [
        "Please, note: this is just a version of the same code as in the other notebook  that uses a **pandas dataframe of a SQL database** to store data.\n",
        "\n",
        "It allows to skip the download, installation and setup of SQL software and can be fully executed and reproduced in this cloud environment.\n",
        "\n",
        "\n",
        "Nevertheless, a dataframe cannot fully replace a relational database: for this reason, I would keep the latter for the actual development of the project, and use the dataframe for *illustrating* purposes only."
      ]
    }
  ]
}
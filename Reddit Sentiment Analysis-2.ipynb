{"cells":[{"metadata":{},"cell_type":"markdown","source":"The first preliminary step to performing any kind of sentiment analysis on Reddit data is establishing a Reddit instance via API. This can be done with the Python Reddit API Wrapper (PRAW), see documentation: https://praw.readthedocs.io/en/latest/\n\nIn order to access the API, a Reddit account is needed, login details below.\nE-mail: barbara.balcon@studbocconi.it\nUsername: thesis_3078976\nPassword: class_of_2021\n\nI created an application at the following link: https://www.reddit.com/prefs/apps\nName: Sentiment Analysis\nI selected 'script' (Script for personal use. Will only have access to the developers accounts\ndescription)\nDescription: Data will be used to perform sentiment analysis\nAbout url: blank\nRedirect url: http://www.example.com/unused/redirect/url (this is empty)\n\nAfter creating the app, the following is generated.\nID: L_wWPUNiMBmn1Q\nSecret: bUYKyV21W3xXK4GzXsY5tsNzpG3pRw\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#import of the relevant libraries \nimport praw\nimport pandas as pd\nfrom praw.models import MoreComments\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import RegexpTokenizer\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.stem import PorterStemmer\nfrom nltk import FreqDist\nimport emoji #remove emoji\nimport re #remove links\n#import en_core_web_sm\nimport spacy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create a reddit connection with reddit api details\nreddit=praw.Reddit(client_id='L_wWPUNiMBmn1Q', client_secret='bUYKyV21W3xXK4GzXsY5tsNzpG3pRw', user_agent='ua')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The following pulls the five hottest posts in the subreddit wallstreetbets, printing the title and ID of each"},{"metadata":{"trusted":true},"cell_type":"code","source":"subreddit=reddit.subreddit('wallstreetbets')\nfor submission in subreddit.hot(limit=5):\n    print(submission.title)\n    print('Submission ID = ', submission.id, '\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"markdown","source":"I am about to collect data in a SQL database, I use MySQL as a databse management system. In order to do so, after installing and setting up MySQL on my machine, we need to import a python package here and to connect to the server.\n\nThen, we create a database for storing the reddit data (which will be stramed in a subsequent step)."},{"metadata":{"trusted":true},"cell_type":"code","source":"import mysql.connector #importing the Python package to use MySQL\nfrom unidecode import unidecode #a package for dealing with Unicode\nimport datetime \nimport time #packages for handling date and time data\n\n#below I am connecting to the server I have started on my machine\nmydb=mysql.connector.connect(host='MacBook-Air-di-Barbara.local', \n                             user='root',\n                            passwd='class_of_2021')\n\nmycursor=mydb.cursor()\n\n#creation of a database for storing reddit data \nmycursor.execute('CREATE DATABASE IF NOT EXISTS reddit_data')\n\n#creating variables we are about to create instances of when analysing sentiment\nmycursor.execute(\"\"\"CREATE TABLE IF NOT EXISTS reddit_data.reddit_data_sentiment\n                (date_time DATETIME,\n                subreddit VARCHAR(500),\n                title VARCHAR(500),        \n                body VARCHAR(2000),\n                author VARCHAR(500),\n                sentiment DECIMAL(5,4)  \n                )\n                \"\"\")\n\n#pushing the data to the database (we will use this variable in the next code snippet)\nsqlFormula = \"INSERT INTO reddit_data.reddit_data_sentiment (date_time, subreddit, title, body, author, sentiment) VALUES (%s, %s, %s, %s, %s, %s)\"\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we are ready to actually stream comments from Reddit and perform sentiment analysis via VADER (Valence Aware Dictionary and sEntiment Reasoner). It is an open-source tool that was designed for social media specifically, it is lexicon and rule-based.\n\nIt returns a polarity score (-1, +1) for each post: a normalized, weighted composite score that acts as a metric of the overall sentiment of a given post.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\nanalyzer= SentimentIntensityAnalyzer() #just an abbreviation \n\nwhile True:\n    try:\n        \n        subreddit = reddit.subreddit('wallstreetbets')\n        for comment in subreddit.stream.comments(skip_existing=True):\n                current_time = datetime.datetime.now()\n                subreddit = str(comment.subreddit)\n                author = str(comment.author)\n                title = str(comment.link_title)\n                body = str(comment.body)\n                \n                vs = analyzer.polarity_scores(unidecode(body))\n                sentiment = vs['compound'] #we are interested in the compound score\n                db = (current_time,subreddit,title,body,author,sentiment)\n                mycursor.execute(sqlFormula, db)\n                mydb.commit()\n'''We keep an exception so that in case of error we do not hit\nthe API multiple times''' \n    except Exception as e:\n        print(str(e))\n        time.sleep(10)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":2}